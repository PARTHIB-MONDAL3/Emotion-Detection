{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuS4o86a2Cr0",
        "outputId": "2c202b86-238d-4fef-8c53-7a9182c820f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neattext\n",
            "  Downloading neattext-0.1.3-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading neattext-0.1.3-py3-none-any.whl (114 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/114.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: neattext\n",
            "Successfully installed neattext-0.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install neattext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import joblib\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import neattext.functions as nfx\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "csVpXX9x2OSK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejg8I8-12OOy",
        "outputId": "5eecc5c6-cc76-4bcf-e5f1-ea469fc7bb62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Load Data ===\n",
        "csv_file = \"/content/Emotion_dataset.csv\"  # Ensure your CSV has 'text' and 'label' columns\n",
        "if not os.path.exists(csv_file):\n",
        "    raise FileNotFoundError(f\"CSV file '{csv_file}' not found.\")\n",
        "\n",
        "# Read the CSV\n",
        "# Try reading with different encodings if utf-8 fails\n",
        "try:\n",
        "    df = pd.read_csv(csv_file, encoding='utf-8')\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file, encoding='latin-1')\n",
        "    except UnicodeDecodeError:\n",
        "        df = pd.read_csv(csv_file, encoding='cp1252')\n",
        "\n",
        "\n",
        "if 'text' not in df.columns or 'label' not in df.columns:\n",
        "    raise ValueError(\"CSV must contain 'text' and 'label' columns.\")"
      ],
      "metadata": {
        "id": "0-FgjW_l2OMy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Preprocessing Function ===\n",
        "def preprocess_text(text):\n",
        "    # Ensure text is a string before processing\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = nfx.remove_userhandles(text)\n",
        "    text = nfx.remove_punctuations(text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return \" \".join(words)\n"
      ],
      "metadata": {
        "id": "A3WscbIp2OKb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing\n",
        "df['clean_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# === Feature Extraction ===\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['clean_text'])\n",
        "y = df['label']\n",
        "\n",
        "# === Train/Test Split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "_Tld9RC82OHS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Model Training ===\n",
        "# Change the model here to Support Vector Classifier (SVC)\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained SVC model\n",
        "joblib.dump(model, \"emotion_model_svc.pkl\")\n",
        "\n",
        "# === Evaluation ===\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy Score: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpDfR-MI2OEp",
        "outputId": "19e897f7-c3e1-4c09-e887-c78bc8e06f7d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.00      0.00      0.00         3\n",
            "       Happy       0.44      1.00      0.62         4\n",
            "         Sad       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.50        10\n",
            "   macro avg       0.48      0.44      0.37        10\n",
            "weighted avg       0.48      0.50      0.40        10\n",
            "\n",
            "\n",
            "Accuracy Score: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Model Training ===\n",
        "# Change the model here to Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained SVC model\n",
        "joblib.dump(model, \"emotion_model_rf.pkl\")\n",
        "\n",
        "# === Evaluation ===\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy Score: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wvcwQtx2OBx",
        "outputId": "f50466ff-6b31-40c6-e374-913f46f6f20c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       1.00      0.33      0.50         3\n",
            "       Happy       0.50      1.00      0.67         4\n",
            "         Sad       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.60        10\n",
            "   macro avg       0.83      0.56      0.56        10\n",
            "weighted avg       0.80      0.60      0.57        10\n",
            "\n",
            "\n",
            "Accuracy Score: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Prediction Function ===\n",
        "def predict_emotion(text):\n",
        "    clean_text = preprocess_text(text)\n",
        "    vect = vectorizer.transform([clean_text])\n",
        "    return model.predict(vect)[0]"
      ],
      "metadata": {
        "id": "qT_cGiR_2N-5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Sample Predictions ===\n",
        "samples = [\n",
        "    \"I just won the game!\",\n",
        "    \"I'm so sad and depressed.\",\n",
        "    \"I can't tolerate this anymore!\"\n",
        "]\n",
        "\n",
        "print(\"\\nSample Predictions:\")\n",
        "for s in samples:\n",
        "    print(f\"Text: '{s}' → {predict_emotion(s)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX4Tz39u2N8B",
        "outputId": "fd14b958-fd8c-4152-ac52-eefe8cf446fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Predictions:\n",
            "Text: 'I just won the game!' → Happy\n",
            "Text: 'I'm so sad and depressed.' → Sad\n",
            "Text: 'I can't tolerate this anymore!' → Angry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_input=input(\"Enter the text:\")\n",
        "print(predict_emotion(text_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFIVGEgp2N5J",
        "outputId": "ef8493e0-b787-421b-f18f-2e0a2e925b59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text:Celebrate this amazing win!\n",
            "Happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_input=input(\"Enter the text:\")\n",
        "print(predict_emotion(text_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB5oPWXx2N25",
        "outputId": "b750ccdd-19c6-43e8-feb5-45977900a0c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text:I'm not okay today.\n",
            "Sad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_input=input(\"Enter the text:\")\n",
        "print(predict_emotion(text_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDgcqTCe2N0B",
        "outputId": "ab00d9f2-174c-4ff6-8a90-5b3384c3888e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text:I feel like punching the wall!\n",
            "Angry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#                                                             End of the Project"
      ],
      "metadata": {
        "id": "rVeIRONL3XeP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}